%% Cleaning
clear;
clc;
warning('off');

%% Load features and labels
load('bestCCnetfeatureswithlables45fc8.mat'); % Ensure this file contains 'features' and 'labels'

%% Start timer for total execution
totalTimeStart = tic;

%% Parameters for Bees Algorithm
numBees = 30; % Number of bees
numFeatures = size(features, 2); % Total number of features
maxIter = 100; % Maximum number of iterations

%% Initialize Population
population = rand(numBees, numFeatures) > 0.9; % Initialize with a sparsity
for i = 1:numBees
    if sum(population(i, :)) == 0
        population(i, randi(numFeatures)) = true; % Ensure at least one feature is selected
    end
end

%% Evaluate Initial Fitness
fitness = zeros(numBees, 1);
for i = 1:numBees
    fitness(i) = EvaluateFitness(features(:, population(i, :)), labels);
end

%% Timing for feature selection
featureSelectionTimeStart = tic;

%% Main Loop of Bees Algorithm
for iter = 1:maxIter
    % Employed Bees Phase
    for i = 1:numBees
        newSolution = Mutate(population(i, :));
        newFitness = EvaluateFitness(features(:, newSolution), labels);
        if newFitness > fitness(i)
            population(i, :) = newSolution;
            fitness(i) = newFitness;
        end
    end

    % Onlooker Bees Phase
    probability = fitness / sum(fitness);
    for i = 1:numBees
        k = RouletteWheelSelection(probability);
        newSolution = Mutate(population(k, :));
        newFitness = EvaluateFitness(features(:, newSolution), labels);
        if newFitness > fitness(k)
            population(k, :) = newSolution;
            fitness(k) = newFitness;
        end
    end

    % Scout Bees Phase
    for i = 1:numBees
        if ShouldBecomeScout(fitness(i))
            population(i, :) = rand(1, numFeatures) > 0.5;
            fitness(i) = EvaluateFitness(features(:, population(i, :)), labels);
        end
    end

    % Log best fitness of this iteration
    convergenceHistory(iter) = max(fitness);
end

%% Compute feature selection computation time
featureSelectionTime = toc(featureSelectionTimeStart);

%% Select best solution
[bestFitness, bestIdx] = max(fitness);
bestFeatures = population(bestIdx, :);

%% Classifier Models
selectedFeatures = features(:, bestFeatures);
numFolds = 5; % Number of folds for cross-validation
classifiers = {
    @fitcknn,
    @(X, Y) fitcecoc(X, Y, 'Learners', templateSVM('KernelFunction', 'linear'), 'Coding', 'onevsall'),
    @fitctree,
    @fitcnb
};
names = {'K-Nearest Neighbors', 'Support Vector Machine', 'Decision Tree', 'Naive Bayes'};

for i = 1:length(classifiers)
    cvmodel = crossval(classifiers{i}(selectedFeatures, labels), 'KFold', numFolds);
    figure;
    confusionchart(cvmodel.Y, kfoldPredict(cvmodel));
    title([names[i}, ' Confusion Matrix']);
end

%% Measure total computation time
totalTime = toc(totalTimeStart);  % Stop timer for total execution

%% Plot Convergence History
figure;
plot(1:maxIter, convergenceHistory, 'b-o');
xlabel('Iteration');
ylabel('Best Fitness Value');
title('Convergence History of Bees Algorithm');
grid on;

%% Display execution times
fprintf('Feature selection time: %.4f seconds.\n', featureSelectionTime);
fprintf('Total execution time: %.4f seconds.\n', totalTime);


%%supporting functions
function fit = EvaluateFitness(subsetFeatures, labels)
    if isempty(subsetFeatures) || size(subsetFeatures, 2) == 0
        fit = 0;  % Assign a low fitness to encourage selection of non-empty subsets
        return;
    end
    model = fitcknn(subsetFeatures, labels, 'NumNeighbors', 5);
    cvmodel = crossval(model, 'KFold', 5);
    fit = 1 - kfoldLoss(cvmodel);
end

function newSol = Mutate(solution)
    mutationPoint = randi(length(solution));
    newSol = solution;
    if sum(solution) == 1 && solution(mutationPoint) == true
        newMutationPoint = randi(length(solution));
        while newMutationPoint == mutationPoint
            newMutationPoint = randi(length(solution));
        end
        newSol(newMutationPoint) = true;
    else
        newSol(mutationPoint) = ~newSol(mutationPoint);
    end
end

function idx = RouletteWheelSelection(probability)
    cumulative = cumsum(probability);
    r = rand();
    idx = find(cumulative >= r, 1, 'first');
end

function scout = ShouldBecomeScout(fitness)
    scout = fitness < 0.7;  % Example threshold
end
%% Plot Convergence History
figure;
plot(1:maxIter, convergenceHistory, 'b-o');
xlabel('Iteration');
ylabel('Best Fitness Value');
title('Convergence History of Bees Algorithm');
grid on;

%% Display execution times
fprintf('Feature selection time: %.4f seconds.\n', featureSelectionTime);


fprintf('Total execution time: %.4f seconds.\n', totalTime);
